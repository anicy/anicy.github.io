---
title:   "配置hadoop2.x 伪分布式集群"
description:   "happy wife, happy life ..."
keywords:   hadoop
category:   Study
tags:   [hadoop] 
---


{% include JB/setup %}

###准备材料
- hadoop二进制安装包

###安装步骤
- 配置ssh免密码登陆
```bash
#安装ssh
sudo apt-get install openssh-server
#生成非对称秘钥对
ssh-keygen -t rsa -P ""
#一直回车，会在.ssh目录下生成 id_rsa  id_rsa.pub 两个文件
cd .ssh
cat id_rsa.pub >> authorized_keys
chmod 600 authorized_keys
#ok 这也就可以实现认证，其他机器如果要实现免密码登陆，只需要把登陆机器的公钥写入到被登陆机器的授权文件 authorized_keys 里面即可。
```

- 添加java路径
切换到目录 hadoop2.5.2/etc/hadoop
在如下的文件里面都需要引入java路径，将本机的java安装目录，写入到这几个文件里面。
hadoop-env.sh   yarn-env.sh  mapred-env.sh 

- 修改slave
添加slave节点，可以输入slave节点的ip或者机器名。建议用机器名，因为ip地址可能会发生变化。
```
#for example
slave1
slave2
```

- core-site.xml(这些都是最小配置，其他的配置可以参照官网)
```
<configuration>
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://Spark-desktop:9000</value>
		<description>the name of the default file system</description>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/home/spark/hadoopdata/tmp</value>
		<description>a base for other temporary directories</description>
	</property>
</configuration>
```

- hdfs-site.xml
```xml
<configuration>
	<property>
		<name>dfs.replication</name>
		<value>1</value>
	</property>
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/home/spark/hadoopdata/dfs/name</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/home/spark/hadoopdata/dfs/data</value>
	</property>
</configuration>
```

- mapred-site.xml
```
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>
```

- yarn-site.xml
```
<configuration>
	<property>
		<name>yarn.resourcemanager.hostname</name>
		<value>spark-desktop</value>
	</property>
	<property>
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
</configuration>
```

至此，基本配置完毕，如果进行分布式安装，需要整个hadoop二进制包分发到各个节点。具体可以使用
`scp` 命令进行分发和复制。

完成复制之后，第一次使用hadoop分布式集群的时候需要进行文件格式化。

###验证安装
- 格式化hdfs文件系统
进入到hadoop/bin 目录  执行 `./hadoop namenode -format` 即可完成文件系统的格式化。
- 启动hdfs
hadoop2.x将某些控制命令放到了sbin下了。切换到hadoop/sbin 启动hdfs
`./start-dfs.sh`
- 启动yarn集群 `./start-yarn.sh`
- 上传文件 `hadoop fs -put localfile  hdfs-dir/file`
可以通过jps看到启动的进程，也可以通过web界面进行对集群的监控和管理
http://localhost:50070
http://localhost:8088

###后续
启动集群


![](http://needpp.qiniudn.com/2014/12/28/b2186522-8e61-11e4-a385-f23c9156bf7b.png)


整个集群状态

![](http://needpp.qiniudn.com/2014/12/28/b1221ad2-8e61-11e4-a385-f23c9156bf7b.png)


应用状态

![](http://needpp.qiniudn.com/2014/12/28/afc3cca8-8e61-11e4-a385-f23c9156bf7b.png)


文件系统


![](http://needpp.qiniudn.com/2014/12/28/b0c805a6-8e61-11e4-a385-f23c9156bf7b.png)



