---
layout: post
title: "数据挖掘项目总结文档"
description: ""
keywords: weka,ml,machine learning ,ml
category: data mining
tags: [weka,ml,machine learning ,ml]
---


### 数据挖掘项目总结文档

#### 1、文档概述

#####1.1 编写目的
记录本次实验思路及流程，备忘用。
#####1.2 适用对象
个人学习总结，描述有偏差之处陆续更进。

<!-- more -->



#### 2、业务理解与分析定义

#####2.1 需求概述
针对传统网络入侵检测系统存在的误判以及漏检情况，采用数据挖掘的指导思想，通过大量的攻击样本数据进行知识发现，本次实验采用的kdd99数据集，其中包含了大量的模拟攻击行为。
>1998年美国国防部高级规划署（DARPA）在MI T林肯实验室进行了一项入侵检测评估项目。林肯实验
室建立了模拟美国空军局域网的一个网络环境，收集了9周时间的 TCPdump() 网络连接和系统审计数
据，仿真各种用户类型、各种不同的网络流量和攻击手段，使它就像一个真实的网络环境。这些
TCPdump采集的原始数据被分为两个部分：7周时间的训练数据 (*) 大概包含5,000,000多个网络连接
记录，剩下的2周时间的测试数据大概包含2,000,000个网络连接记录。  ——[kdd数据集背景介绍]()

值得注意的是随着互联网的飞速发展，各种新的攻击手段以及工具不断涌现，而用这份98年生成的测试数据集来作基线检测缺乏一定的实效性，而今市面上也无任何组织或者团体公布出新的检测标准，学术上也一直沿用这份数据集合来度量入侵检测算法的优劣。

#####2.2 分析目标定义


#####2.3 模型定义

#### 3、数据准备与数据探索

#####3.1 数据准备

本文档采用的数据为kdd99数据集，进行分析探索。数据集合说明参照[kdd99数据集整理-by dcy](#)。

#####3.2 数据分析和探索
具体分析方法可以参照另外一个文档[Weka快速入门-v1.0](#)

#####3.3 数据处理流程图
*数据处理流程图*
                                   ![pic]({{ site.qiniudn }}/kdd99/1.jpg)




#### 4、模型构建

#####4.1 分析思路
参考论文**《基于数据挖掘的入侵检测模型研究_王超峰》**的分析思路。论文将关联规则挖掘算法和基于最小相异度的聚类算法应用于入侵检测，从而设计了一个基于数据挖掘的入侵检测模型，该模型的主要思想是：通过关联规则挖掘算法建立误用信息库并进行误用检测，能快速的检测出已知的入侵行为，但是容易产生漏报，需要进行二次检测；采用最小相异度的聚类算法建立聚类信息库，并进行二次检测，检测出漏报的和未知的入侵行为。 基于数据挖掘的入侵检测模型的关键在于误用信息库和聚类信息库的建立、更新、误用检测和聚类检测几个部分。模型框架如下图所示：

![pic]({{ site.qiniudn }}/kdd99/2.jpg)

#####4.2 建模工具
- weka
- scikit-learing
- spss

#####4.3 建模流程

由于获取到的kdd99数据集已经经过整理成结构话的数据，每条记录包含41个特征属性以及一个分类标签，一共42个字段使用逗号分隔符进行分割。

*示例数据如下所示*

```python
0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00,normal.
0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,19,19,1.00,0.00,0.05,0.00,0.00,0.00,0.00,0.00,normal.
```

将其转化为weka内置arff格式。其中有些属性有所省略，这里只做大概理解，详细格式信息参见[Weka学习总结-v1.0](#)。

```bash
@relation attr

@attribute duration numeric
@attribute protocol_type {tcp,udp,icmp}
@attribute service {http,smtp,finger,domain_u,auth,telnet,ftp,eco_i,ntp_u,ecr_i,other,private,pop_3,ftp_data,rje,time,mtp,link,remote_job,gopher,ssh,name,whois,domain,login,imap4,daytime,ctf,nntp,shell,IRC,nnsp,http_443,exec,printer,efs,courier,uucp,klogin,kshell,echo,discard,systat,supdup,iso_tsap,hostnames,csnet_ns,pop_2,sunrpc,uucp_path,netbios_ns,netbios_ssn,netbios_dgm,sql_net,vmnet,bgp,Z39_50,ldap,netstat,urh_i,X11,urp_i,pm_dump,tftp_u,tim_i,red_i}
@attribute flag {SF,S1,REJ,S2,S0,S3,RSTO,RSTR,RSTOS0,OTH,SH}
@attribute src_bytes numeric
@attribute dst_bytes numeric
......
......
@attribute dst_host_rerror_rate numeric
@attribute dst_host_srv_rerror_rate numeric
@attribute lable {normal.,buffer_overflow.,loadmodule.,perl.,neptune.,smurf.,guess_passwd.,pod.,teardrop.,portsweep.,ipsweep.,land.,ftp_write.,back.,imap.,satan.,phf.,nmap.,multihop.,warezmaster.,warezclient.,spy.,rootkit.}

@data
0,tcp,http,SF,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0,0,0,0,1,0,0,9,9,1,0,0.11,0,0,0,0,0,normal.
0,tcp,http,SF,239,486,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0,0,0,0,1,0,0,19,19,1,0,0.05,0,0,0,0,0,normal.
0,tcp,http,SF,235,1337,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0,0,0,0,1,0,0,29,29,1,0,0.03,0,0,0,0,0,normal.
```


*特征抽取*

根据 Kayacik H G等人在[Selecting features for intrusion detection](http://www.researchgate.net/publication/220919984_Selecting_Features_for_Intrusion_Detection_A_Feature_Relevance_Analysis_on_KDD_99/file/3deec529d20b943102.pdf)这篇文章中所使用的信息增益的方法来选择特征，一方面减少冗余特征、另一方面也可以提高学习速度。
借助开源软件[Weka](http://www.cs.waikato.ac.nz/ml/weka/)，我们可以很容易的在数据集合上选择出相应的和分类标签最相关的特征用来学习，由于我们直接采用kdd提供的10%小数据集合（近400w条连接记录）作为训练集，没有单独提出测试集合，故采用10折交叉验证的方式进行特征选择。

![pic]({{ site.qiniudn }}/kdd99/3.jpg)

**关联分析模块**
生成关联规则
十则交叉验证整个数据集合得到每个特征对于分类属性的一个信息熵，我们设定阈值为0.5，选出大于0.5以上的特征属性进行降为学习。

![pic]({{ site.qiniudn }}/kdd99/4.jpg)


我们发现剩下17个特征以及一个类标签：

![pic]({{ site.qiniudn }}/kdd99/5.jpg)

下面进行关联规则的生成。选择Apriori算法，由于该算法针对是离散型变量，故我们需要再对数据进行离散化处理。完了之后调整Apriori算法相关参数导出关联规则。
![pic]({{ site.qiniudn }}/kdd99/6.jpg)\
图中的蕴含关系则为推导出的**强关联规则**。


生成关联规则之后，进行误用检测的流程图 
![pic]({{ site.qiniudn }}/kdd99/7.jpg)
                                   
**聚类分析模块**
                ![聚类分析模块](./1409217436135.png)
按照分类属性，使用简单聚类方式将数据集分成4个聚类。
![pic]({{ site.qiniudn }}/kdd99/8.jpg)
图中勾出了四个中心点。得到结果仅供演示使用，为了提高速度只选取了1%的数据（49402条记录）。不能代表全局，要定义的中心点的个数也可以另外指定，不断的实验对比，从而确定最优的个数。

#####4.4 模型结果



#### 5、模型评估

#####5.1 模型评估方法
使用分类的正确率来度量。

#####5.2 评估结果
简单采用分类树进行模拟发现，在对经过提取特征的数据进行分类训练，这里采用在原来的训练集合上采用十折交叉验证方式进行评估，分类正确率99.8% ，存在着过拟合现象，由于缺乏测试集合的类标签，无法进行模型的泛化能力（对原数据集合中不曾出现过的类别）检测。总体说来，这些数据集经过非常精细的整理并除去了一些冗余的信息，而且本身包含大量的攻击行为。这是分类正确率如此之高的原因，具体应用的场景能达到一个怎么样的水平以及如何提高分类模型的准确率，还的经过真实数据的检验。

*评估结果*
![pic]({{ site.qiniudn }}/kdd99/9.jpg)

*混淆矩阵*

![pic]({{ site.qiniudn }}/kdd99/10.jpg)


####7、参考资料
- Kayacik H G, Zincir-Heywood A N, Heywood M I. Selecting features for intrusion detection: A feature relevance analysis on KDD 99 intrusion detection datasets[C]//Proceedings of the third annual conference on privacy, security and trust. 2005.
- 王超峰. 基于数据挖掘的入侵检测模型研究[D].青岛理工大学,2010.
- [weka快速入门-v1.0]()
- [kdd99数据集整理-by dcy]()

